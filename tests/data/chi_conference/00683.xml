<article>
<year>2006</year>
<title>Comparing remote gesture technologies for supporting collaborative physical tasks</title>
<author>Kirk, David</author>
<author>Stanton Fraser, Danae</author>
<keyword>CSCW</keyword>
<keyword>hands</keyword>
<keyword>mixed ecologies</keyword>
<keyword>remote gesturing</keyword>
<abstract>The design of remote gesturing technologies is an area of growing interest. Current technologies have taken differing approaches to the representation of remote gesture. It is not clear which approach has the most benefit to task performance. This study therefore compared performance in a collaborative physical (assembly) task using remote gesture systems constructed with combinations of three different gesture formats (unmediated hands only, hands and sketch and digital sketch only) and two different gesture output locations (direct projection into a worker's task space or on an external monitor). Results indicated that gesturing with an unmediated representation of the hands leads to faster performance with no loss of accuracy. Comparison of gesture output locations did not find a significant difference between projecting gestures and presenting them on external monitors. These results are discussed in relation to theories of conversational grounding and the design of technologies from a 'mixed ecologies' perspective.</abstract>
</article>