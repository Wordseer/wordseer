<article>
<year>2010</year>
<title>SHRIMP: solving collision and out of vocabulary problems in mobile predictive input with motion gesture</title>
<author>Wang, Jingtao</author>
<author>Zhai, Shumin</author>
<author>Canny, John</author>
<keyword>camera phones</keyword>
<keyword>dictionary-based disambiguation</keyword>
<keyword>gestures</keyword>
<keyword>mobile devices</keyword>
<keyword>mobile phones</keyword>
<keyword>multitap</keyword>
<keyword>predictive input</keyword>
<keyword>t9</keyword>
<keyword>text input</keyword>
<abstract>Dictionary-based disambiguation (DBD) is a very popular solution for text entry on mobile phone keypads but suffers from two problems: 1. the resolution of encoding collision (two or more words sharing the same numeric key sequence) and 2. entering out-of-vocabulary (OOV) words. In this paper, we present SHRIMP, a system and method that addresses these two problems by integrating DBD with camera based motion sensing that enables the user to express preference through a tilting or movement gesture. SHRIMP (Small Handheld Rapid Input with Motion and Prediction) runs on camera phones equipped with a standard 12-key keypad. SHRIMP maintains the speed advantage of DBD driven predictive text input while enabling the user to overcome DBD collision and OOV problems seamlessly without even a mode switch. An initial empirical study demonstrates that SHRIMP can be learned very quickly, performed immediately faster than MultiTap and handled OOV words more efficiently than DBD.</abstract>
<article>
