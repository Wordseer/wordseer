<article>
<year>2008</year>
<title>Blindsight: eyes-free access to mobile phones</title>
<author>Li, Kevin A.</author>
<author>Baudisch, Patrick</author>
<author>Hinckley, Ken</author>
<keyword>devices</keyword>
<keyword>eyes-free</keyword>
<keyword>mobile phone</keyword>
<keyword>non-speech audio</keyword>
<keyword>user interfaces</keyword>
<abstract>Many mobile phones integrate services such as personal calendars. Given the social nature of the stored data, however, users often need to access such information as part of a phone conversation. In typical non-headset use, this re-quires users to interrupt their conversations to look at the screen. We investigate a counter-intuitive solution: to avoid the need for interruption we replace the visual interface with one based on auditory feedback. Surprisingly, this can be done without interfering with the phone conversation. We present blindSight, a prototype application that replaces the traditionally visual in-call menu of a mobile phone. Users interact using the phone keypad, without looking at the screen. BlindSight responds with auditory feedback. This feedback is heard only by the user, not by the person on the other end of the line. We present the results of two user studies of our prototype. The first study verifies that useful keypress accuracy can be obtained for the phone-at-ear position. The second study compares the blindSight system against a visual baseline condition and finds a preference for blindSight.</abstract>
</article>