<article>
<year>2005</year>
<title>Effects of task properties, partner actions, and message content on eye gaze patterns in a collaborative task</title>
<author>Ou, Jiazhi</author>
<author>Oh, Lui Min</author>
<author>Yang, Jie</author>
<author>Fussell, Susan R.</author>
<keyword>collaborative work</keyword>
<keyword>computer-supported</keyword>
<keyword>conversational analysis</keyword>
<keyword>empirical studies</keyword>
<keyword>eye-tracking</keyword>
<keyword>gesture</keyword>
<keyword>video conferencing</keyword>
<keyword>video mediated communication</keyword>
<abstract>Helpers providing guidance for collaborative physical tasks shift their gaze between the workspace, supply area, and instructions. Understanding when and why helpers gaze at each area is important both for a theoretical understanding of collaboration on physical tasks and for the design of automated video systems for remote collaboration. In a laboratory experiment using a collaborative puzzle task, we recorded helpers' gaze while manipulating task complexity and piece differentiability. Helpers gazed toward the pieces bay more frequently when pieces were difficult to differentiate and less frequently over repeated trials. Preliminary analyses of message content show that helpers tend to look at the pieces bay when describing the next piece and at the workspace when describing where it goes. The results are consistent with a grounding model of communication, in which helpers seek visual evidence of understanding unless they are confident that they have been understood. The results also suggest the feasibility of building automated video systems based on remote helpers' shifting visual requirements.</abstract>
<article>
