<article>
<year>2010</year>
<title>High-precision magnification lenses</title>
<author>Appert, Caroline</author>
<author>Chapuis, Olivier</author>
<author>Pietriga, Emmanuel</author>
<keyword>focus+context</keyword>
<keyword>lenses</keyword>
<keyword>navigation</keyword>
<keyword>quantization</keyword>
<keyword>selection</keyword>
<abstract>Focus+context interfaces provide in-place magnification of a region of the display, smoothly integrating the focus of attention into its surroundings. Two representations of the data exist simultaneously at two different scales, providing an alternative to classical pan \&#38; zoom for navigating multi-scale interfaces. For many practical applications however, the magnification range of focus+context techniques is too limited. This paper addresses this limitation by exploring the quantization</i> problem: the mismatch between visual and motor precision in the magnified region. We introduce three new interaction techniques that solve this problem by integrating fast navigation and high-precision interaction in the magnified region. Speed</i> couples precision to navigation speed. Key</i> and Ring</i> use a discrete switch between precision levels, the former using a keyboard modifier, the latter by decoupling the cursor from the lens' center. We report on three experiments showing that our techniques make interacting with lenses easier while increasing the range of practical magnification factors, and that performance can be further improved by integrating speed-dependent visual behaviors.</abstract>
</article>