<article>
<year>2008</year>
<title>Emotion rating from short blog texts</title>
<author>Gill, Alastair J.</author>
<author>Gergle, Darren</author>
<author>French, Robert M.</author>
<author>Oberlander, Jon</author>
<keyword>affect</keyword>
<keyword>computer-mediated communication</keyword>
<keyword>emotion</keyword>
<keyword>language</keyword>
<abstract>Being able to automatically perceive a variety of emotions from text alone has potentially important applications in CMC and HCI that range from identifying mood from online posts to enabling dynamically adaptive interfaces. However, such ability has not been proven in human raters or computational systems. Here we examine the ability of naive raters of emotion to detect one of eight emotional categories from 50 and 200 word samples of real blog text. Using expert raters as a 'gold standard', naive-expert rater agreement increased with longer texts, and was high for ratings of joy, disgust, anger and anticipation, but low for acceptance and 'neutral' texts. We discuss these findings in light of theories of CMC and potential applications in HCI.</abstract>
</article>